{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b47f5aa8",
   "metadata": {},
   "source": [
    "# Tuberculosis Classification CNN Model with Attention\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d197d2",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d5aa956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16750ae7",
   "metadata": {},
   "source": [
    "## Dataset Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b49f0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Define dataset directories\n",
    "DATASET_DIR = os.path.join('.', 'tuberculosis-dataset')\n",
    "NORMAL_DIR  = os.path.join(DATASET_DIR, 'Normal')\n",
    "TB_DIR      = os.path.join(DATASET_DIR, 'Tuberculosis')\n",
    "\n",
    "print(\"NORMAL_DIR exists?\", os.path.exists(NORMAL_DIR))\n",
    "print(\"TB_DIR exists?\", os.path.exists(TB_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136957b9",
   "metadata": {},
   "source": [
    "## Load and Preprocess Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1eda13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "all_images = []\n",
    "all_labels = []\n",
    "IMAGE_SIZE = 256\n",
    "\n",
    "# Load Normal images (label = 0)\n",
    "for fname in os.listdir(NORMAL_DIR):\n",
    "    filepath = os.path.join(NORMAL_DIR, fname)\n",
    "    img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "        all_images.append(img)\n",
    "        all_labels.append(0)\n",
    "\n",
    "# Load Tuberculosis images (label = 1)\n",
    "for fname in os.listdir(TB_DIR):\n",
    "    filepath = os.path.join(TB_DIR, fname)\n",
    "    img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "        all_images.append(img)\n",
    "        all_labels.append(1)\n",
    "\n",
    "all_images = np.array(all_images)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "print(\"Images shape:\", all_images.shape)\n",
    "print(\"Labels shape:\", all_labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f4aa22",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e927e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    all_images, all_labels, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Convert from [0,255] -> [0,1] for training\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test  = X_test.astype('float32')  / 255.0\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fea82c1",
   "metadata": {},
   "source": [
    "## Balance Dataset with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "819d4c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "smote_engine = SMOTE(random_state=42)\n",
    "\n",
    "# Flatten images for SMOTE (shape: (n_samples, 256*256))\n",
    "num_train_samples = X_train.shape[0]\n",
    "X_train_2D = X_train.reshape(num_train_samples, -1)\n",
    "\n",
    "X_train_resampled_2D, y_train_resampled = smote_engine.fit_resample(X_train_2D, y_train)\n",
    "\n",
    "# Reshape back to (N, H, W, 1)\n",
    "X_train_resampled = X_train_resampled_2D.reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 1)\n",
    "\n",
    "print(\"After SMOTE, X_train_resampled shape:\", X_train_resampled.shape)\n",
    "print(\"After SMOTE, y_train_resampled shape:\", y_train_resampled.shape)\n",
    "unique_vals, counts = np.unique(y_train_resampled, return_counts=True)\n",
    "print(\"Label distribution:\", dict(zip(unique_vals, counts)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9987319",
   "metadata": {},
   "source": [
    "## Dataset Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de681fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Before SMOTE distribution\n",
    "plt.subplot(1, 2, 1)\n",
    "original_vals, original_counts = np.unique(y_train, return_counts=True)\n",
    "sns.barplot(x=['Normal', 'Tuberculosis'], y=original_counts, palette='viridis')\n",
    "plt.title('Class Distribution Before SMOTE')\n",
    "plt.ylabel('Number of Samples')\n",
    "for i, count in enumerate(original_counts):\n",
    "    plt.text(i, count + 5, str(count), ha='center')\n",
    "\n",
    "# After SMOTE distribution\n",
    "plt.subplot(1, 2, 2)\n",
    "resampled_vals, resampled_counts = np.unique(y_train_resampled, return_counts=True)\n",
    "sns.barplot(x=['Normal', 'Tuberculosis'], y=resampled_counts, palette='viridis')\n",
    "plt.title('Class Distribution After SMOTE')\n",
    "plt.ylabel('Number of Samples')\n",
    "for i, count in enumerate(resampled_counts):\n",
    "    plt.text(i, count + 5, str(count), ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Test set distribution\n",
    "plt.figure(figsize=(7, 5))\n",
    "test_vals, test_counts = np.unique(y_test, return_counts=True)\n",
    "sns.barplot(x=['Normal', 'Tuberculosis'], y=test_counts, palette='viridis')\n",
    "plt.title('Test Set Class Distribution')\n",
    "plt.ylabel('Number of Samples')\n",
    "for i, count in enumerate(test_counts):\n",
    "    plt.text(i, count + 2, str(count), ha='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97df82ac",
   "metadata": {},
   "source": [
    "## Visualize Sample Images from Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ac8104f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Visualize sample images from each class\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Find indices of normal and TB samples\n",
    "normal_indices = np.where(y_train_resampled == 0)[0]\n",
    "tb_indices = np.where(y_train_resampled == 1)[0]\n",
    "\n",
    "# Sample 5 images from each class\n",
    "normal_samples = np.random.choice(normal_indices, 5, replace=False)\n",
    "tb_samples = np.random.choice(tb_indices, 5, replace=False)\n",
    "\n",
    "# Plot Normal samples\n",
    "for i, idx in enumerate(normal_samples):\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    img = np.squeeze(X_train_resampled[idx])\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"Normal #{i+1}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "# Plot TB samples\n",
    "for i, idx in enumerate(tb_samples):\n",
    "    plt.subplot(2, 5, i+6)\n",
    "    img = np.squeeze(X_train_resampled[idx])\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"Tuberculosis #{i+1}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Sample Images from Training Dataset\", y=1.05, fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b071c583",
   "metadata": {},
   "source": [
    "## Image Intensity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f1fbede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Analyze image intensity distributions\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Randomly sample images for analysis\n",
    "n_samples = min(100, len(normal_indices), len(tb_indices))\n",
    "normal_analysis = np.random.choice(normal_indices, n_samples, replace=False)\n",
    "tb_analysis = np.random.choice(tb_indices, n_samples, replace=False)\n",
    "\n",
    "# Compute mean intensity histograms for each class\n",
    "normal_hist = np.zeros(50)\n",
    "tb_hist = np.zeros(50)\n",
    "\n",
    "for idx in normal_analysis:\n",
    "    img = np.squeeze(X_train_resampled[idx])\n",
    "    hist, _ = np.histogram(img, bins=50, range=(0, 1))\n",
    "    normal_hist += hist\n",
    "    \n",
    "for idx in tb_analysis:\n",
    "    img = np.squeeze(X_train_resampled[idx])\n",
    "    hist, _ = np.histogram(img, bins=50, range=(0, 1))\n",
    "    tb_hist += hist\n",
    "\n",
    "# Normalize the histograms\n",
    "normal_hist = normal_hist / n_samples\n",
    "tb_hist = tb_hist / n_samples\n",
    "\n",
    "# Plot the average intensity histograms\n",
    "plt.subplot(2, 2, 1)\n",
    "bin_edges = np.linspace(0, 1, 51)\n",
    "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "plt.plot(bin_centers, normal_hist, label='Normal', color='blue', linewidth=2)\n",
    "plt.plot(bin_centers, tb_hist, label='Tuberculosis', color='red', linewidth=2)\n",
    "plt.legend()\n",
    "plt.title('Average Pixel Intensity Distribution')\n",
    "plt.xlabel('Pixel Intensity')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Compute mean and standard deviation of pixel values for each class\n",
    "normal_means = [np.mean(np.squeeze(X_train_resampled[idx])) for idx in normal_analysis]\n",
    "normal_stds = [np.std(np.squeeze(X_train_resampled[idx])) for idx in normal_analysis]\n",
    "tb_means = [np.mean(np.squeeze(X_train_resampled[idx])) for idx in tb_analysis]\n",
    "tb_stds = [np.std(np.squeeze(X_train_resampled[idx])) for idx in tb_analysis]\n",
    "\n",
    "# Plot mean intensity boxplot\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.boxplot(data=[normal_means, tb_means], palette=['blue', 'red'])\n",
    "plt.xticks([0, 1], ['Normal', 'Tuberculosis'])\n",
    "plt.title('Distribution of Mean Image Intensities')\n",
    "plt.ylabel('Mean Intensity')\n",
    "\n",
    "# Plot standard deviation boxplot\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.boxplot(data=[normal_stds, tb_stds], palette=['blue', 'red'])\n",
    "plt.xticks([0, 1], ['Normal', 'Tuberculosis'])\n",
    "plt.title('Distribution of Image Standard Deviations')\n",
    "plt.ylabel('Standard Deviation')\n",
    "\n",
    "# Scatter plot of mean vs std\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.scatter(normal_means, normal_stds, alpha=0.6, label='Normal', color='blue')\n",
    "plt.scatter(tb_means, tb_stds, alpha=0.6, label='Tuberculosis', color='red')\n",
    "plt.xlabel('Mean Intensity')\n",
    "plt.ylabel('Standard Deviation')\n",
    "plt.title('Mean vs. Standard Deviation')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ec98ee",
   "metadata": {},
   "source": [
    "## 6. Create PyTorch Dataset and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c1b657c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "class TBChestXrayDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset class for Tuberculosis Chest X-ray classification,\n",
    "    capable of applying transforms (data augmentation).\n",
    "    \"\"\"\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            images (np.array): (N, H, W, 1) or (N, H, W) array of grayscale images.\n",
    "            labels (np.array): (N,) array of labels (0 or 1).\n",
    "            transform (callable, optional).\n",
    "        \"\"\"\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Extract image, label\n",
    "        raw_image = self.images[idx]  # shape: (H, W, 1) or (H, W)\n",
    "        label_val = self.labels[idx].astype('float32')\n",
    "\n",
    "        # If shape is (H, W, 1), we can squeeze to (H, W)\n",
    "        if len(raw_image.shape) == 3 and raw_image.shape[2] == 1:\n",
    "            raw_image = np.squeeze(raw_image, axis=-1)\n",
    "\n",
    "        # Convert to PIL Image for transforms\n",
    "        pil_image = Image.fromarray((raw_image * 255).astype('uint8'), mode='L')\n",
    "\n",
    "        if self.transform:\n",
    "            img_tensor = self.transform(pil_image)  # transforms yield torch.Tensor [C,H,W]\n",
    "        else:\n",
    "            # Default: turn into PyTorch tensor with shape [1,H,W]\n",
    "            img_tensor = torch.tensor(raw_image, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        label_tensor = torch.tensor(label_val, dtype=torch.float32)\n",
    "        return img_tensor, label_tensor\n",
    "\n",
    "# Define transforms for data augmentation\n",
    "train_transforms = T.Compose([\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomVerticalFlip(p=0.1),  # Some TB patterns are orientation-sensitive but adding slight variability\n",
    "    T.RandomRotation(degrees=15),\n",
    "    T.RandomAffine(degrees=0, translate=(0.05, 0.05), scale=(0.95, 1.05)),  # Simulate different patient positioning\n",
    "    T.ColorJitter(brightness=0.15, contrast=0.15),  # Simulate different X-ray exposure settings\n",
    "    T.RandomAutocontrast(p=0.2),  # Helps with different X-ray machine calibrations\n",
    "    T.ToTensor(),\n",
    "    T.RandomErasing(p=0.2, scale=(0.02, 0.1))  # Simulate occlusions/small artifacts\n",
    "])\n",
    "\n",
    "# For test set, just convert to tensor (no augmentation)\n",
    "test_transforms = T.Compose([\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TBChestXrayDataset(X_train_resampled, y_train_resampled, transform=train_transforms)\n",
    "test_4D = X_test.reshape(-1, IMAGE_SIZE, IMAGE_SIZE, 1)\n",
    "test_dataset  = TBChestXrayDataset(test_4D, y_test, transform=test_transforms)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(\"Number of training samples:\", len(train_dataset))\n",
    "print(\"Number of testing samples:\", len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc505a5c",
   "metadata": {},
   "source": [
    "## Spatial Attention and CNN Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78207cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "class SimpleAttentionCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    A variant of the SimpleCNN that includes a SpatialAttention block.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(SimpleAttentionCNN, self).__init__()\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),  # Added padding\n",
    "            nn.BatchNorm2d(16),  # Add BatchNorm\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            \n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),  # Add BatchNorm\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),  # Add BatchNorm\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "\n",
    "        # Spatial attention module\n",
    "        self.spatial_attention = SpatialAttention(kernel_size=7)\n",
    "\n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 30 * 30, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Extract deep features\n",
    "        features = self.feature_extractor(x)           # [B,64,30,30]\n",
    "        attention_map = self.spatial_attention(features) # [B,1,30,30]\n",
    "\n",
    "        # Apply attention\n",
    "        attended_features = features * attention_map   # Element-wise multiplication\n",
    "\n",
    "        # Classify\n",
    "        output = self.classifier(attended_features)    # [B,1]\n",
    "        return output, attention_map\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleAttentionCNN().to(device)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f45de4",
   "metadata": {},
   "source": [
    "## Loss Function and Optimizer Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76b50595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add weight decay to combat overfitting\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "# Change learning rate scheduler to monitor validation metrics instead of training\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='max', factor=0.1, patience=2, min_lr=1e-5, verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0884de1",
   "metadata": {},
   "source": [
    "## Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a2f117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(network, dataloader, optimizer, criterion, device):\n",
    "    network.train()\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    for batch_images, batch_labels in dataloader:\n",
    "        batch_images = batch_images.to(device)\n",
    "        batch_labels = batch_labels.to(device).view(-1, 1)  # shape: [B,1]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass (we only need 'output' for loss)\n",
    "        outputs, _ = network(batch_images)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * batch_images.size(0)\n",
    "        \n",
    "        predicted_classes = (outputs >= 0.5).float()  # threshold at 0.5\n",
    "        correct_predictions += (predicted_classes == batch_labels).sum().item()\n",
    "        total_samples += batch_labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def evaluate_model(network, dataloader, criterion, device):\n",
    "    network.eval()\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_images, batch_labels in dataloader:\n",
    "            batch_images = batch_images.to(device)\n",
    "            batch_labels = batch_labels.to(device).view(-1, 1)\n",
    "            \n",
    "            outputs, _ = network(batch_images)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            \n",
    "            total_loss += loss.item() * batch_images.size(0)\n",
    "            \n",
    "            predicted_classes = (outputs >= 0.5).float()\n",
    "            correct_predictions += (predicted_classes == batch_labels).sum().item()\n",
    "            total_samples += batch_labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd05d12",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80a264b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "num_epochs = 25  # Increased from 10\n",
    "best_accuracy = 0.0\n",
    "best_model_path = \"tb_chest_xray_attention_best.pt\"\n",
    "patience = 4  # For early stopping\n",
    "patience_counter = 0\n",
    "\n",
    "# Split some training data for validation\n",
    "train_size = int(0.85 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_subset, val_subset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "train_loader_split = DataLoader(train_subset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=16, shuffle=False)\n",
    "\n",
    "print(f\"Training on {train_size} samples, validating on {val_size} samples\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Train\n",
    "    train_loss, train_acc = train_one_epoch(\n",
    "        model, train_loader_split, optimizer, loss_function, device\n",
    "    )\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_acc = evaluate_model(\n",
    "        model, val_loader, loss_function, device\n",
    "    )\n",
    "    \n",
    "    # Using validation accuracy for LR scheduling\n",
    "    lr_scheduler.step(val_acc)\n",
    "    \n",
    "    print(f\"[Epoch {epoch+1}/{num_epochs}] \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    # Save the best model based on validation accuracy\n",
    "    if val_acc > best_accuracy:\n",
    "        best_accuracy = val_acc\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"Model improved at epoch {epoch+1}, saved to {best_model_path}\")\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cff680c",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a8fe3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.eval()\n",
    "\n",
    "all_predictions = []\n",
    "all_ground_truths = []\n",
    "all_raw_outputs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images_batch, labels_batch in test_loader:\n",
    "        images_batch = images_batch.to(device)\n",
    "        labels_batch = labels_batch.to(device)\n",
    "        \n",
    "        outputs, attention_map = model(images_batch)\n",
    "        preds = (outputs >= 0.5).float()\n",
    "        \n",
    "        all_predictions.extend(preds.cpu().numpy().flatten())\n",
    "        all_ground_truths.extend(labels_batch.cpu().numpy().flatten())\n",
    "        all_raw_outputs.extend(outputs.cpu().numpy().flatten())\n",
    "\n",
    "print(\"CLASSIFICATION REPORT:\")\n",
    "print(classification_report(all_ground_truths, all_predictions, digits=4))\n",
    "\n",
    "print(\"CONFUSION MATRIX:\")\n",
    "print(confusion_matrix(all_ground_truths, all_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df217ba",
   "metadata": {},
   "source": [
    "## Confusion Matrix Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b63a4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Confusion Matrix as a heatmap\n",
    "cm = confusion_matrix(all_ground_truths, all_predictions)\n",
    "class_names = ['Normal', 'Tuberculosis']\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, \n",
    "            yticklabels=class_names)\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.title('Confusion Matrix')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9db56a4",
   "metadata": {},
   "source": [
    "## ROC Curve Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50b30675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, _ = roc_curve(all_ground_truths, all_raw_outputs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"AUC-ROC Score: {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9b3716",
   "metadata": {},
   "source": [
    "## Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a0a1e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precision, recall, _ = precision_recall_curve(all_ground_truths, all_raw_outputs)\n",
    "avg_precision = average_precision_score(all_ground_truths, all_raw_outputs)\n",
    "plt.plot(recall, precision, color='green', lw=2, label=f'AP = {avg_precision:.4f}')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average Precision Score: {avg_precision:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af1a302",
   "metadata": {},
   "source": [
    "## Classification Metrics by Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3b58217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Classification Report as a heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "report = classification_report(all_ground_truths, all_predictions, target_names=class_names, \n",
    "                             output_dict=True, digits=4)\n",
    "report_data = []\n",
    "for i, class_name in enumerate(class_names):\n",
    "    metrics = report[class_name]\n",
    "    report_data.append([metrics['precision'], metrics['recall'], metrics['f1-score']])\n",
    "\n",
    "report_df = pd.DataFrame(report_data, index=class_names, \n",
    "                       columns=['Precision', 'Recall', 'F1-Score'])\n",
    "sns.heatmap(report_df, annot=True, fmt='.4f', cmap='Greens')\n",
    "plt.title('Classification Metrics by Class')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print overall metrics\n",
    "print(f\"Overall Metrics:\")\n",
    "print(f\"Accuracy: {report['accuracy']:.4f}\")\n",
    "print(f\"Macro F1-Score: {report['macro avg']['f1-score']:.4f}\")\n",
    "print(f\"Weighted F1-Score: {report['weighted avg']['f1-score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb02f6d",
   "metadata": {},
   "source": [
    "## Utility Function for Attention Map Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1cbe9500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to get sample predictions with attention maps\n",
    "def get_sample_prediction_with_attention(model, dataloader, num_samples=3, device=device):\n",
    "    model.eval()\n",
    "    samples = []\n",
    "    class_samples = {0: [], 1: []}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs, attention_maps = model(images)\n",
    "            preds = (outputs >= 0.5).float()\n",
    "            \n",
    "            # Get indices where prediction matches ground truth\n",
    "            correct_indices = (preds.flatten() == labels).nonzero(as_tuple=True)[0]\n",
    "            \n",
    "            for idx in correct_indices:\n",
    "                class_label = int(labels[idx].item())\n",
    "                if len(class_samples[class_label]) < num_samples:\n",
    "                    class_samples[class_label].append({\n",
    "                        'image': images[idx].cpu(),\n",
    "                        'attention': attention_maps[idx].cpu(),\n",
    "                        'pred': outputs[idx].item(),\n",
    "                        'label': class_label\n",
    "                    })\n",
    "            \n",
    "            if all(len(samples) >= num_samples for samples in class_samples.values()):\n",
    "                break\n",
    "                \n",
    "    return class_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea8f56f",
   "metadata": {},
   "source": [
    "## Normal Class with Attention Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67f7da56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Get samples\n",
    "class_samples = get_sample_prediction_with_attention(model, test_loader, num_samples=3)\n",
    "class_names = ['Normal', 'Tuberculosis']\n",
    "\n",
    "# Plot normal class samples\n",
    "fig, axes = plt.subplots(1, 6, figsize=(18, 4))\n",
    "class_idx = 0  # Normal class\n",
    "\n",
    "for i, sample in enumerate(class_samples[class_idx]):\n",
    "    # Original image\n",
    "    ax = axes[i*2]\n",
    "    img = sample['image'].squeeze().numpy()\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(f\"{class_names[class_idx]}\\nConf: {sample['pred']:.2f}\")\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Attention map overlaid\n",
    "    ax = axes[i*2+1]\n",
    "    attention = sample['attention'].squeeze().numpy()\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    attention_masked = np.ma.masked_where(attention < 0.5, attention)\n",
    "    ax.imshow(attention_masked, cmap='jet', alpha=0.6)\n",
    "    ax.set_title(f\"Attention Map\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Normal Class Predictions with Attention Maps\", y=1.05, fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47dc729",
   "metadata": {},
   "source": [
    "## Tuberculosis Class with Attention Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd66450e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Plot tuberculosis class samples\n",
    "fig, axes = plt.subplots(1, 6, figsize=(18, 4))\n",
    "class_idx = 1  # Tuberculosis class\n",
    "\n",
    "for i, sample in enumerate(class_samples[class_idx]):\n",
    "    # Original image\n",
    "    ax = axes[i*2]\n",
    "    img = sample['image'].squeeze().numpy()\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(f\"{class_names[class_idx]}\\nConf: {sample['pred']:.2f}\")\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Attention map overlaid\n",
    "    ax = axes[i*2+1]\n",
    "    attention = sample['attention'].squeeze().numpy()\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    attention_masked = np.ma.masked_where(attention < 0.5, attention)\n",
    "    ax.imshow(attention_masked, cmap='jet', alpha=0.6)\n",
    "    ax.set_title(f\"Attention Map\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Tuberculosis Class Predictions with Attention Maps\", y=1.05, fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0879e8cd",
   "metadata": {},
   "source": [
    "## Attention Heatmap Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c79c3f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Create a more detailed visualization of attention heatmaps\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Select one sample from each class\n",
    "normal_sample = class_samples[0][0]\n",
    "tb_sample = class_samples[1][0]\n",
    "\n",
    "# Normal class\n",
    "plt.subplot(2, 2, 1)\n",
    "normal_img = normal_sample['image'].squeeze().numpy()\n",
    "plt.imshow(normal_img, cmap='gray')\n",
    "plt.title(f\"Normal X-ray\\nConfidence: {normal_sample['pred']:.4f}\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "normal_attention = normal_sample['attention'].squeeze().numpy()\n",
    "plt.imshow(normal_attention, cmap='hot')\n",
    "plt.colorbar(label='Attention Weight')\n",
    "plt.title(\"Normal Attention Heatmap\")\n",
    "plt.axis('off')\n",
    "\n",
    "# TB class\n",
    "plt.subplot(2, 2, 3)\n",
    "tb_img = tb_sample['image'].squeeze().numpy()\n",
    "plt.imshow(tb_img, cmap='gray')\n",
    "plt.title(f\"Tuberculosis X-ray\\nConfidence: {tb_sample['pred']:.4f}\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "tb_attention = tb_sample['attention'].squeeze().numpy()\n",
    "plt.imshow(tb_attention, cmap='hot')\n",
    "plt.colorbar(label='Attention Weight')\n",
    "plt.title(\"Tuberculosis Attention Heatmap\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Attention Heatmap Comparison: Normal vs. Tuberculosis\", y=0.98, fontsize=16)\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580ce3ff",
   "metadata": {},
   "source": [
    "## Class Precision Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82e8d501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Visualization of class precision metrics calculated from model predictions\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "# Calculate precision for each class from model predictions\n",
    "overall_precision = precision_score(all_ground_truths, all_predictions, average=None)\n",
    "normal_precision = overall_precision[0] * 100  # Class 0 (Normal)\n",
    "tb_precision = overall_precision[1] * 100      # Class 1 (TB)\n",
    "\n",
    "# Alternative calculation from confusion matrix if needed\n",
    "cm = confusion_matrix(all_ground_truths, all_predictions)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "normal_precision_cm = tn / (tn + fn) * 100 if (tn + fn) > 0 else 0\n",
    "tb_precision_cm = tp / (tp + fp) * 100 if (tp + fp) > 0 else 0\n",
    "\n",
    "# For visualization - use the precision_score results\n",
    "classes = ['Normal (Class 0)', 'TB (Class 1)']\n",
    "precision_values = [normal_precision, tb_precision]\n",
    "colors = ['#5DA5DA', '#FAA43A']  # Blue for Normal, Orange for TB\n",
    "\n",
    "# Create the visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(classes, precision_values, color=colors, width=0.6)\n",
    "\n",
    "# Add percentage labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "             f'{height:.2f}%', ha='center', fontweight='bold')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Class', fontsize=12)\n",
    "plt.ylabel('Precision (%)', fontsize=12)\n",
    "plt.title('Model Precision by Class', fontsize=14, fontweight='bold')\n",
    "plt.ylim(0, 105)  # Set y-axis limit to accommodate text labels\n",
    "\n",
    "# Add grid lines for better readability\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add text box with precision information\n",
    "textstr = '\\n'.join([\n",
    "    'Classification Precision:',\n",
    "    f'• Normal (Class 0): {normal_precision:.2f}%',\n",
    "    f'• TB (Class 1): {tb_precision:.2f}%'\n",
    "])\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=0.8)\n",
    "plt.text(0.5, 0.02, textstr, transform=plt.gca().transAxes, \n",
    "         fontsize=12, verticalalignment='bottom', horizontalalignment='center',\n",
    "         bbox=props)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print the calculated values\n",
    "print(\"Model Precision Metrics:\")\n",
    "print(f\"- Normal (Class 0): {normal_precision:.2f}% precision\")\n",
    "print(f\"- TB (Class 1): {tb_precision:.2f}% precision\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 891819,
     "sourceId": 2332307,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30746,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1390.689335,
   "end_time": "2024-07-14T22:57:20.495719",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-14T22:34:09.806384",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
